---
title: "Area-level variables"
format: 
  html:
    toc: true
editor: source
params:
  eval_all: FALSE
  harvest: FALSE
editor_options: 
  chunk_output_type: console
---

```{r echo=FALSE}
# Recollect data from the sources?
if ("try-error" %in% class(try(params$eval_all)))
  params <- list(eval_all = FALSE, harvest = FALSE)
```

```{r}
#| label: setup
#| echo: false
#| warning: false
#| message: false
#| error: false

# Libraries
pacman::p_load(
  purrr,
  tidyr,
  readr,
  pins,
  readxl,
  arrow,
  glue,
  stringr,
  forcats,
  ggplot2,
  scales,
  patchwork,
  sf,
  mapview,
  flextable,
  ftExtra,
  knitr,
  htmltools,
  lubridate,
  bdl # Poland's database API  
)

library(dplyr)

# Chunk setup
knitr::opts_chunk$set(
  echo = FALSE,
  message = FALSE,
  warning = FALSE,
  error = FALSE
)

# Loading locally-developed
list.files("R", pattern="*.R$", full.names=TRUE, ignore.case=TRUE) |> 
  walk(source)

# Raw data root
root_raw <- "./data/raw"
root_temp <- "./data/temp"
root_clean <- "./data/clean"

# Data-storage boards
bd_raw <- root_raw |> file.path("api") |> board_folder(versioned = T)
bd_aux <- root_temp |> board_folder(versioned = T)
bd_clean <- root_clean |> board_folder(versioned = T)

# bd_geom <- file.path("data-clean", "geom") |> board_folder(versioned = T)

# Years range
range <- c(2011, 2019:2030)
```

# Area-level variables from the Central Statistical Office

The Polish database of area-level variables integrates data from multiple official sources, ensuring a comprehensive overview of demographic, economic, and social conditions. A key foundation of the database comes from the [Central Statistical Office](https://stat.gov.pl/en/), which conducts Population and Housing Censuses and maintains the [TERYT Register](https://api.stat.gov.pl/Home/TerytApi?lang=en), a territorial division system essential for spatial analysis. Civil registration data, including birth and death certificates and the PESEL Register, further enhance demographic insights. Additionally, local governance bodies such as Gmina Offices and Provincial Offices contribute administrative records relevant to local policymaking.
 
Financial and social security data play a crucial role in understanding economic conditions. [The Ministry of Finance ](https://www.gov.pl/web/finance) oversees the Tax Information System, which tracks taxation records across regions. [The Social Insurance Institution](https://lang.zus.pl/) manages national social security programs, providing insights into employment and pension distributions. Meanwhile, the [Ministry of Family and Social Policy](https://www.gov.pl/web/family) administers welfare programs, including the [National Family Benefits Monitoring System](https://www.gov.pl/web/family/family-benefits) and the Central Register of Data on Recipients of Benefits from the Alimony Fund. Institutional Foster Care and Day-Support Centres further contribute to data on social support structures.
 
Sector-specific administrative data enhance the database’s breadth. The Ministry of Development and Technology (https://www.gov.pl/web/development-technology) provides records on urban planning and economic development, while the Ministry of Justice (https://www.gov.pl/web/justice) contributes legal and judicial data. Health-related insights stem from the Ministry of Health, the Chief Pharmaceutical Inspectorate (https://www.gov.pl/web/chief-pharmaceutical-inspectorate), and the National Health Fund (https://www.nfz-lodz.pl/), which track public health services and pharmaceutical regulation. Finally, the Energy Regulatory Office (https://www.ure.gov.pl/en) supplies crucial data on energy markets and infrastructure, further enriching the database’s capacity for policy analysis.

This section describes steps of raw data loading and pre-processing by groups of variables. It is overall relies on the [API](https://api.stat.gov.pl/Home/BdlApi) provided by the NSO which is available trough the R package [`bdl`](https://cran.r-project.org/package=bdl).

```{r eval=TRUE}
#| label: load-metadata
meta_groups <-
  root_raw |> file.path("pl-metadata.xlsx") |> readxl::read_xlsx(sheet = "pl") |> 
  fill(Category) |> 
  select(Category, id_indicator, Indicator, Source, Metadata, `Link to Source`)

meta_vars <- 
  root_raw |> file.path("pl-metadata.xlsx") |> readxl::read_xlsx(sheet = "pl-index") |> 
  fill(id_indicator, Indicator) |> 
  mutate(across(c(Indicator, var_name), ~ as_factor(.)))
```

```{r eval=TRUE}
#| label: load-geom
geoms <- bd_aux |> pin_read("geometries")
```

```{r eval=TRUE}
#| label: api-reload
# Loading data through an API
if (params$harvest) {
  to_do <- meta_vars$var_id_api |> unique()
  done <- bd_raw |> pin_list()
  to_do <- to_do[!to_do %in% done]
  to_do |> pl_collect_api(bd_raw)
}
```

```{r eval=TRUE}
#| label: raw-data-compilation
if (params$eval_all) {
  all_dta <-
    bd_raw |> pin_list() |>
    map_dfr(~ {
      bd_raw |> pin_read(.x) |>
        mutate(var_id_api = .x) |>
        select(any_of(c("id", "year", "val", "var", "var_id_api"))) |> 
        mutate(year = as.integer(year))
    }) |> 
    mutate(var_id_api = ifelse(!is.na(var), var, var_id_api)) |>
    mutate(var_id_api = as.character(var_id_api),
           var_id_api = ifelse(is.na(var_id_api), var_id , var_id_api)) |>
    left_join(
      meta_vars |>
        mutate(
          var_id_api = ifelse(is.na(var_id_api), var_id , var_id_api),
          var_id_api = as.character(var_id_api)) |>
        select(var_id_api, var = var_id),
      by = join_by(var_id_api), suffix = c("", ".y")
    ) |>
    mutate(var = ifelse(is.na(var), var.y, var)) |> 
    select(id, year, var, val)
  
  bd_aux |> pin_write(all_dta, name = "all_dta", type = "parquet")
  metadata <- list(meta_groups = meta_groups, meta_vars = meta_vars)
  bd_aux |> pin_write(metadata, name = "metadata", type = "rds")
}
```

## Variable-specific overview

```{r echo = FALSE}
div(flextable_html_dependency())
```

```{r calc-var-overview, results='asis', echo = FALSE}
all_dta <- bd_aux |> pin_read(name = "all_dta")
meta_categ <- 
  meta_groups |> 
  select(Category, id_indicator, Indicator, Source, Metadata) |> 
  left_join(meta_vars |> 
              select(id_indicator, var_id_api, var_id, var_name, var_units, `Sample survey`),
            by = join_by(id_indicator)) |> 
  filter(!is.na(var_id )) |> 
  mutate(across(c(Category, id_indicator, Indicator, var_id, var_name),
                ~ as_factor(.))) 
range <-
  all_dta |>  
  pl_decode_id() |>
  group_by(var, level) |>
  summarise(
    n = sum(!is.na(val)) |> number(1, big.mark = ""),
    year_min = min(year) |> str_sub(3, 4),
    year_max = max(year) |> str_sub(3, 4)
  ) |>
  ungroup()  |>
  filter(level %in% str_c("level", 4:7)) |> 
  pl_rename_levels() |>
  mutate(range = str_c(year_min, ":", year_max)) |>
  select(-year_min, -year_max, -n) |>
  pivot_wider(names_from = level,
              values_from = range,
              values_fill = "n/a")

meta_categ |> group_by(cat1 = Category) |> nest() |> pull(data) |> 
  walk(~{
    one_categ <- .x
    text1 <- str_c("## ", unique(as.character(one_categ$Category)), "\n\n\n\n")
    cat(text1)
    
    tbl1 <-
      one_categ |>
      ungroup() |>
      select(
        Indicator,
        Source,
        Variable = var_name,
        Units = var_units,
        `Sample` = `Sample survey`,
        var = var_id
      ) |>
      left_join(range, join_by(var)) |> 
      mutate(
        Indicator = str_c(Indicator, ". Source: ", Source),
        Variable = ifelse(
          !is.na(Sample),
          str_c(as.character(Variable), " (Sample-based)"),
          as.character(Variable)
        )
      ) |>
      select(-Source, -Sample, -var) |>
      select(Indicator, everything()) |> 
      as_grouped_data(groups = "Indicator") |> 
      as_flextable(hide_grouplabel = TRUE) |>
      bold(~ !is.na(Indicator)) |>
        FitFlextableToPage()
    tbl1 <- set_caption(tbl1,"Variables by category and data source")
    
    # # Get N missing
    # cat_dta <-
    #   all_dta |>
    #   semi_join(one_categ |> rename(var = var_id), by = join_by(var)) |>
    #   select(-any_of("var_id_api"))
    # 
    # 
    # 
    # tbl2 <- cat_dta |> get_format_missing(geoms) |> autofit()
    # tbl2 <- set_caption(tbl2,"N missing values by variable and administrative level")
    
    # c(text1, flextable_to_rmd(tbl1), flextable_to_rmd(tbl2))
    flextable_to_rmd(tbl1)
    # flextable_to_rmd(tbl2)
    
    cat("\n\n\n\n")
    # # browser()
    # var_to_make <- cat_dta$var |> unique() 
    # nvar <- min(length(var_to_make), 2)
    # var_to_make <- var_to_make |> sample(nvar) 
    # 
    # var_to_make |> walk( ~ {
    #   cat_dta |>
    #     plot_var(
    #       var_choice = .x,
    #       focus = 3:5,
    #       geoms,
    #       years = max(cat_dta$year)
    #     ) |> print()
    # })
  }) 
```

# Other data sources

## Night time lights

This data requires an extraction of raster data with the harmonized annual NTL time series.
@fig-ntl shows example of the data. 
Potential sources are Google Earth Engine [NOAA vIIRS DNB MONTHLY V1 VCMCFG](https://developers.google.com/earth-engine/datasets/catalog/NOAA_VIIRS_DNB_MONTHLY_V1_VCMCFG).

```{r ntl-extr, eval=FALSE}
if (params$harvest) {
  library(terra)
  library(tidyterra)
  library(exactextractr)
  
  # # Cropping poland form the EU map
  # in_ext <- geoms$level0 |> st_transform(st_crs(4326)) |> ext()
  # ntl <-
  #   c(
  #     "eu-ntl-annual-mean-463.850000000000-0000009984.tif",
  #     "eu-ntl-annual-mean-463.850000000000-0000000000.tif"
  #   ) |>
  #   map( ~ {
  #     # browser()
  #     ntl0 <- root_raw |> file.path("ntl", "eu", .x) |> rast()
  #     window(ntl0) <- ext(in_ext)
  #
  #     ntl0
  #   }) |>
  #   reduce(merge)
  #
  # ntl |>
  #   terra::writeRaster(filename = root_raw |> file.path("ntl", "pl", "ntl.tif"),
  #                      overwrite = TRUE)
  # # Checking the image:
  # ggplot() +
  #   geom_spatraster(data = ntl, aes(fill = ntl_mean_v12020)) +
  #   coord_sf(crs = 3857) +
  #   scale_fill_grass_c(palette = "celsius")
  
  ntl <- root_raw |> file.path("ntl", "pl", "ntl.tif") |> rast()
  pl_ntl <-
    geoms |>
    map( ~ {
      exactextractr::exact_extract(
        x = ntl,
        y = .x |> st_transform(st_crs(ntl)),
        fun = "mean",
        force_df  = TRUE,
        append_cols = TRUE
      ) |>
        as_tibble()
    }) |>
    map(~ {
      .x |>
        pivot_longer(cols = contains("mean"),
                     names_to = "var",
                     values_to = "val") |>
        mutate(year = str_extract(var, "20\\d{2}"), var = "ntl_mean_mask") |>
        select(id, year, var, val)
    }) |>
    reduce(bind_rows) |>
    arrange(id, year)
  
  bd_raw |> pin_write(pl_ntl, name = "ntl", type = "parquet")
}
```

```{r}
#| label:  fig-ntl
#| fig-cap: 2023 Annual average NTL 
pop <- 
  bd_raw |> pin_read("ntl")  |> pl_decode_id() |>
  filter(type_LAU %in% c("0", "1", "2", "3")) |>
  select(id, year, var, val)

pop |> filter(year == 2023) |>  plot_var("ntl_mean_mask", geoms = geoms, meta = meta_vars)
```

## Cell phone coverage

Cell phone network coverage maps are generated based on the OpenCellID data. @fig-cell shows examples of such data.

```{r}
if (params$harvest) {
  dta_cell <-
    "C:\\Users\\wb532966\\OneDrive - WBG\\EPL\\EU-Povery-Map\\EUPM-data\\gis-data\\OpenCellID\\cell_towers_2025-02-28-T000000.csv" |> 
    read_csv() |> 
    filter(mcc == 260)%>%
    st_as_sf(coords = c("lon", "lat"), crs = 4326) |> 
    st_transform(st_crs(geoms$level0)) 
  
  dta_cell2 <- 
    geoms |> 
    map(~{dta_cell |> st_join(.x) |> select(-name) |> filter(!is.na(id))}) |>  
    bind_rows() |> 
    # filter(!is.na(id)) |>
    # count(radio) |> 
    mutate(across(c(created, updated), ~ year(as.Date(as.POSIXct(., origin="1970-01-01"))))) |> 
    st_drop_geometry() |> 
    group_by(id, radio, created, updated) |> 
    summarise(range_km = sum(range , na.rm = TRUE),
              n = sum(!is.na(range) , na.rm = TRUE)) |> 
    ungroup()
  
  dta_cell3 <- 
    c(2009:2025) |> 
    map(~{
      dta_cell2 |>
        filter(created <= .x, updated >= .x) |>
        group_by(radio) |> 
        nest() |> 
        mutate(data = map(data, ~{
          .x |> 
            right_join(geoms |>
                         bind_rows() |>
                         st_drop_geometry() |>
                         select(-name),
                       join_by(id))
          })) |> 
        unnest(data) |> 
        ungroup() |> 
        mutate(year = .x) |> 
        group_by(id, year, radio) |> 
        summarise(range_km = sum(range_km) / 1000000,
                  n = sum(n), .groups = "drop") 
    }) |> 
    bind_rows() |> 
    pivot_longer(c(range_km, n)) |> 
    mutate(var = str_c(tolower(radio ), "_", name)) |> 
    select(id, year, var, val = value) |> 
    mutate(val = ifelse(is.na(val), 1, val))
  
  # dta_cell3 |>
  #   pl_decode_id() |>
  #   filter(type_LAU %in% c("0", "1", "2", "3")) |>
  #   # select(id, year, var, val = n) |> 
  #   plot_var("lte_n", geoms, years = 2024)
  
  bd_raw |> pin_write(dta_cell3, name = "gsm", type = "parquet")
}

```

```{r}
#| label:  fig-cell
#| fig-cap: Cell network coverage
bd_raw |> pin_read("gsm")  |> pl_decode_id() |>
  filter(type_LAU %in% c("0", "1", "2", "3")) |>
  select(id, year, var, val) |>  plot_var("lte_n", geoms, meta_vars)
```

