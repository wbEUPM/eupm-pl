---
title: "Righthand side variables preparation"
authors: 
  - "Eduard Bukin"
format: 
  html:
    fig-width: 14
    fig-height: 9
    fig-retina: true
editor: source
bibliography: references.bib
editor_options: 
  chunk_output_type: console
---

```{r}
#| label: setup
#| echo: false
#| warning: false
#| message: false
#| error: false

# Chunk setup
knitr::opts_chunk$set(
  echo = FALSE,
  message = FALSE,
  warning = FALSE,
  error = FALSE
)

pacman::p_load(
  sf,
  knitr,
  pins,
  scales,
  modelsummary,
  flextable,
  correlation,
  datawizard,
  patchwork,
  tidyverse
  )

# Loading locally-developed
list.files("R", pattern = "*.R$", full.names = TRUE, ignore.case = TRUE) |>
  walk(~ suppressMessages(source(.x)))

# Raw data root
root_raw <- "./data/raw"
root_temp <- "./data/temp"
root_clean <- "./data/clean"

# Data-storage boards
bd_raw <- root_raw |> file.path("api") |> board_folder(versioned = T)
bd_aux <- root_temp |> board_folder(versioned = T)
bd_clean <- root_clean |> board_folder(versioned = T)
```


```{r var-name-set}
area_var <- "id"
year_var <- "year"
year_range <- 2019:2023
directpov <- "pov"
directvar <- "vardir"
```

## Overview

In this script we prepare our right hand side variables that are used in the subsequent steps of the small area estimation and perform its exploratory analysis. 
This includes:

-   Loading and reshaping RHS variables

-   Computing economically sound ratios, constructing complex variables and performing linear transformation

We also load the dependent variable (direct estimates) of poverty and its variance for the exploratory purposes. 

```{r dta-load-direct}
pov_direct <- bd_clean |> pin_read("pov_direct") |> 
  rename(id = subcode) |> filter(type == "arop") |> 
  mutate(estimate = "Direct")
```

## Right hand side (RHS) variables

Right hand side (RHS) variables i.e. indicators representative at the level of the target area for each area consist of two components: data and the metadata.

Data must be prepared in the wide format, where each column represents an individual variable and row represent observations for each area and in one year. Specifically columns are:

-   `id` regional identifier used to match RHS variables with regions and poverty estimates;
-   `year` year for which observations are used;
-   `x1`, `x2`, `x3`, ..., `xn` are the RHS variables described in the metadata.

> Note that sometimes survey data used for calculating the poverty estimates reports income and corresponding poverty rates with the 1 year lag. THerefore, combining RHS variables with poverty rates requires carefully adjusting the year of the RHS variabels. 

Metadata table describes each variable and provides a short, self-explaining name, used in tables and regression tables across the subsequent analysis.

### Loading RHS data

```{r dta-load-rhs}
#| echo: true
file_name <- "Auxiliary variables (edited v6).xlsx"

rhs_meta_0 <-
  file.path(root_raw, "data-other", file_name) |>
  readxl::read_excel(sheet = 2) |> 
  select(var = Variable, name = `Variable (in English) abbrevation`) |> 
  mutate(var = str_to_lower(var))

rhs_dta_0 <- 
  suppressMessages(file.path(root_raw, "data-other", file_name) |>
      readxl::read_excel()) 

new_names <- 
  rhs_dta_0 |> slice(1) |> t() |> as.data.frame() |>
  rownames_to_column() |> as_tibble() |> 
  mutate(rowname = ifelse(str_detect(rowname, "\\.{2,}"), NA_character_, rowname)) |> 
  fill(rowname) |> 
  mutate(rowname = str_to_lower(rowname),
         rowname = ifelse(!is.na(V1), str_c(rowname,"__", V1), rowname)) |> 
  pull(rowname)

rhs_dta_0 <- 
  rhs_dta_0 |> 
  slice(-1) |> 
  (\(x){colnames(x) <- new_names; x})() |> 
  select(-no., -subregion) |> 
  pivot_longer(
    cols = matches("\\d{4}"), 
    values_transform = \(x) suppressWarnings(as.numeric(x))
    ) |> 
  filter(!is.na(value)) |> 
  separate(name, into = c("var", "year")) |> 
  mutate(year = as.numeric(year)) |> 
  pivot_wider(names_from = "var", values_from = "value")
```

Exemplary structure of the RHS variables and their metadata:

```{r dta-str-rhs}
#| echo: true
rhs_dta_0 |> select(1:10) |> glimpse()
rhs_meta_0 |> glimpse()
```

### RHS variables preparation

At this stage we compute (if needed) new variables making sure that those which are used in the SAE analysis are uniquely and appropriately identifies and document in the metadata.

```{r var-preparation}
#| echo: true
rhs_dta <-
  rhs_dta_0 |> 
  mutate(
    # Compute new variables here
    x101 = x4 / x3 # Share of Working Age pop in the region,
  ) |> 
  mutate(year = year + 1) |> 
  left_join(pov_direct |> 
              filter(type == "arop") |> 
              select(id, year, pov, SE = SD, CV, N), 
            by = join_by(id, year)) |> 
  select(id, year, pov, SE, CV, N, everything()) |> 
  select(-x16, -x33) |> 
  filter(year %in% year_range)

# Remember to document new variables following the example below
rhs_meta <- 
  tribble(
    ~var, ~name,
    "x101", "Workage pop share",
    "pov", "Poverty rate (direct est.)",
    "SE", "Standard Error (direct est.)",
    "CV", "Coef. of var. (direct est.)",
    "N", "N obs. (direct est.)",
  ) |> 
  bind_rows(rhs_meta_0)

rhs_dta_long <- 
  rhs_dta |>
  pivot_longer(c(pov, SE, CV, N, contains("x")),
               names_to = "var",
               cols_vary = "slowest") |>
  left_join(rhs_meta, by = join_by(var)) |>
  mutate(name = str_c(var, " ", name) |> as_factor()) |>
  mutate(year = as.character(year)) 
```

## Exploratory analysis

@tbl-rhs-descr-stats provides the summary statistics for the RHS variables after we computed additional ones. @tbl-rhs-descr-stats-year presents year-specific averages, while @tbl-rhs-descr-stats-log does the averages after the logarithm transformation. 

```{r tbl-rhs-descr-stats}
#| tbl-cap: Descriptive statistics of the RHS variables for all years
rhs_dta_long  |>
  (\(x) bind_rows(x |> mutate(year = "All years"), x))() |>
  filter(year == "All years") |>
  mutate(year = as_factor(year)) |>
  datasummary(
    formula = name  ~ value * (Mean + SD + Min + P50 + Max),
    output = "flextable",
    data = _
  ) |>
  FitFlextableToPage() |> 
  width(1, 3)
```

```{r tbl-rhs-descr-stats-year}
#| tbl-cap: Means by years
rhs_dta_long |> 
  datasummary(
    formula = name  ~ year * (value * (Mean)) ,
    output = "flextable",
    data = _
  ) |>
  FitFlextableToPage() |> 
  width(1, 3)
```

We perform logarithm transformation of all contentious variables, where maximum is above 10 and the difference between min and maximum exceeds 10 times.

```{r dta-lin-transform}
#| echo: true

var_to_log <- 
  rhs_dta_long |>
  group_by(year, var) |> 
  summarise(min = min(value), max = max(value)) |> 
  filter(min * 10 < max & max > 10 | max > 100) |> pull(var) |> unique()

rhs_dta_long_log <- 
  rhs_dta_long |>
  group_by(year) |>
  mutate(
    value = ifelse(var %in% var_to_log, log(value), value)
    ) |> 
  ungroup()
```

Descriptive statistics after transformation is in @tbl-rhs-descr-stats-log.

```{r tbl-rhs-descr-stats-log}
#| tbl-cap: Descriptive statistics after log transformation
rhs_dta_long_log |> mutate(type = "log") |> 
  # bind_rows(rhs_dta_long |> mutate(type = "level")) |> 
  (\(x) bind_rows(x |> mutate(year = "All years"), x))() |>
  mutate(year = as_factor(year)) |> #glimpse()
  datasummary(
    formula = name  ~ year * (value * (Mean )),
    output = "flextable",
    data = _
  ) |>
  FitFlextableToPage()
```

## Correlation analysis

Before conducting the variable selection, we explore the correlations between our transformed variables and the poverty rates in @tbl-cor.

```{r tbl-cor}
#| tbl-cap: Correlatoin between poverty rates and key variables
stars.pval <- function(x){
  stars <- c("***", "**", "*", "")
  var <- c(0, 0.01, 0.05, 0.10, 1)
  i <- findInterval(x, var, left.open = T, rightmost.closed = T)
  stars[i]
}

dta_cor <-
  rhs_dta_long_log |> mutate(type = "log") |>
  bind_rows(rhs_dta_long |> mutate(type = "level")) |>
  mutate(year = as.numeric(year) + 1) |>
  left_join(pov_direct |> filter(type == "arop") |> select(id, year, pov),
            by = join_by(id, year)) |>
  mutate(year = as.character(year)) |>
  (\(x) bind_rows(x |> mutate(year = "All years"), x))() |>
  filter(year == "All years") |>
  mutate(year = as_factor(year)) |>
  select(id, year, type, pov, value, name) |>
  filter(str_detect(name, "x\\d")) |>
  pivot_wider(names_from = name, values_from = value) |>
  datawizard::data_group(type) |>
  correlation::correlation() |>
  as_tibble() |>
  filter(Parameter1 == "pov") |>
  mutate(r_abs = abs(r)) |>
  arrange(Group, desc(r_abs)) |>
  mutate(Parameter2 = as_factor(Parameter2) |> fct_reorder(abs(r), .desc = T)) |>
  mutate(stats = str_c(number(r, 0.001), "", stars.pval(p))) |>
  select(Group, Variable = Parameter2, stats) |>
  pivot_wider(names_from = Group, values_from = stats)

dta_cor |>
  flextable() |>
  FitFlextableToPage()
```

## Saving RHS data

Final step is to save the RHS data in the version-controlled way. For that, we employ `pins` package in R and  create a dedicated board for exchanging the clean data sets between scripts. 
In this case, this is a board in `data/clean` folder, where nis with RHS data (`rhs_dta`) and metadata (`rhs_dta`) are created.

> Note: we remove direct-estiamtes related data from this pin to avoid its duplication as it is being produced in another script and saved in the corresponding pin `pov_direct`.

```{r}
rhs_dta_full <- rhs_dta |> select(id, year, matches("x\\d")) 
bd_clean |> pin_write(rhs_dta_full, name = "rhs_dta")
bd_clean |> pin_write(rhs_meta, name = "rhs_meta")
```
